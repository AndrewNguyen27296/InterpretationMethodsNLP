{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Library used.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j60yN6iGZayD"
      },
      "outputs": [],
      "source": [
        "## Normal libs to work with data\n",
        "## adding support for large, multi-dimensional arrays and matrices.\n",
        "import numpy as np \n",
        "## data structures and operations for manipulating numerical tables and time series.\n",
        "import pandas as pd \n",
        "\n",
        "################################################################################\n",
        "# Visualization\n",
        "## the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
        "%matplotlib inline \n",
        "## provides an implicit, MATLAB-like, way of plotting\n",
        "import matplotlib.pyplot as plt \n",
        "## provides a high-level interface for drawing attractive and informative statistical\n",
        "import seaborn as sns\n",
        "\n",
        "################################################################################\n",
        "## Utility\n",
        "## automate data analysis\n",
        "#import pandas_profiling as pp\n",
        "import re\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "################################################################################\n",
        "## Text processing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from stop_words import get_stop_words\n",
        "\n",
        "################################################################################\n",
        "## Feature engineering\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.feature import IDF\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "## utility packs for text processing, i.e. lower case all text\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "## use for classification pyspark models\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "################################################################################\n",
        "## ML models\n",
        "## split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics, linear_model, tree, naive_bayes, neighbors, ensemble, neural_network, svm, decomposition, manifold\n",
        "## Glass box\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from interpret import show\n",
        "\n",
        "################################################################################\n",
        "## Evaluate model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "## pyspark evaluation for classification models\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "################################################################################\n",
        "## SHAP\n",
        "import shap\n",
        "\n",
        "## LIME\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "\n"
      ]
    }
  ]
}