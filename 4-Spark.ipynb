{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_Spark.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Spark architecture for parallel processing"],"metadata":{"id":"C90M1EKQm_Lc"}},{"cell_type":"markdown","source":["## Prepare Spark environment"],"metadata":{"id":"W1-XwsWSnH7O"}},{"cell_type":"code","source":["## install java jdk for spark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"metadata":{"id":"2RfMyJ9unKOJ","executionInfo":{"status":"ok","timestamp":1654261447573,"user_tz":-120,"elapsed":17363,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["## download the necessity package from apache website\n","!wget -q  --trust-server-names  https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz -O file.tgz \n","print(\"Download completed successfully !!!\")\n","\n","## unzip donwloaded file\n","!tar zxvf file.tgz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BmPyE4fnNF7","outputId":"12cd3eef-48fa-4eb6-c0e7-881ef0ff1ada","executionInfo":{"status":"ok","timestamp":1654261453922,"user_tz":-120,"elapsed":6358,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Download completed successfully !!!\n","spark-3.2.1-bin-hadoop3.2/\n","spark-3.2.1-bin-hadoop3.2/LICENSE\n","spark-3.2.1-bin-hadoop3.2/NOTICE\n","spark-3.2.1-bin-hadoop3.2/R/\n","spark-3.2.1-bin-hadoop3.2/R/lib/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/INDEX\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/R.css\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n","spark-3.2.1-bin-hadoop3.2/R/lib/sparkr.zip\n","spark-3.2.1-bin-hadoop3.2/README.md\n","spark-3.2.1-bin-hadoop3.2/RELEASE\n","spark-3.2.1-bin-hadoop3.2/bin/\n","spark-3.2.1-bin-hadoop3.2/bin/beeline\n","spark-3.2.1-bin-hadoop3.2/bin/beeline.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/docker-image-tool.sh\n","spark-3.2.1-bin-hadoop3.2/bin/find-spark-home\n","spark-3.2.1-bin-hadoop3.2/bin/find-spark-home.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.sh\n","spark-3.2.1-bin-hadoop3.2/bin/pyspark\n","spark-3.2.1-bin-hadoop3.2/bin/pyspark.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/pyspark2.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/run-example\n","spark-3.2.1-bin-hadoop3.2/bin/run-example.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-class\n","spark-3.2.1-bin-hadoop3.2/bin/spark-class.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-class2.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-shell\n","spark-3.2.1-bin-hadoop3.2/bin/spark-shell.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-shell2.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-sql\n","spark-3.2.1-bin-hadoop3.2/bin/spark-sql.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-sql2.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-submit\n","spark-3.2.1-bin-hadoop3.2/bin/spark-submit.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/spark-submit2.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/sparkR\n","spark-3.2.1-bin-hadoop3.2/bin/sparkR.cmd\n","spark-3.2.1-bin-hadoop3.2/bin/sparkR2.cmd\n","spark-3.2.1-bin-hadoop3.2/conf/\n","spark-3.2.1-bin-hadoop3.2/conf/fairscheduler.xml.template\n","spark-3.2.1-bin-hadoop3.2/conf/log4j.properties.template\n","spark-3.2.1-bin-hadoop3.2/conf/metrics.properties.template\n","spark-3.2.1-bin-hadoop3.2/conf/spark-defaults.conf.template\n","spark-3.2.1-bin-hadoop3.2/conf/spark-env.sh.template\n","spark-3.2.1-bin-hadoop3.2/conf/workers.template\n","spark-3.2.1-bin-hadoop3.2/data/\n","spark-3.2.1-bin-hadoop3.2/data/graphx/\n","spark-3.2.1-bin-hadoop3.2/data/graphx/followers.txt\n","spark-3.2.1-bin-hadoop3.2/data/graphx/users.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/als/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/als/test.data\n","spark-3.2.1-bin-hadoop3.2/data/mllib/gmm_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/license.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/license.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n","spark-3.2.1-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/kmeans_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/pagerank_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/pic_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/\n","spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n","spark-3.2.1-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n","spark-3.2.1-bin-hadoop3.2/data/streaming/\n","spark-3.2.1-bin-hadoop3.2/data/streaming/AFINN-111.txt\n","spark-3.2.1-bin-hadoop3.2/examples/\n","spark-3.2.1-bin-hadoop3.2/examples/jars/\n","spark-3.2.1-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n","spark-3.2.1-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/examples/src/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/als.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/kmeans.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pagerank.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pi.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sort.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_sessionization.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/python/wordcount.py\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/dataframe.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/als.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/employees.json\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.csv\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.json\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.txt\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/user.avsc\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.avro\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.orc\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.parquet\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/\n","spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n","spark-3.2.1-bin-hadoop3.2/jars/\n","spark-3.2.1-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n","spark-3.2.1-bin-hadoop3.2/jars/JTransforms-3.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/RoaringBitmap-0.9.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/ST4-4.0.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/activation-1.1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/aircompressor-0.21.jar\n","spark-3.2.1-bin-hadoop3.2/jars/algebra_2.12-2.0.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/annotations-17.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/antlr4-runtime-4.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arpack-2.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arrow-format-2.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-core-2.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-netty-2.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/arrow-vector-2.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/automaton-1.11-8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/avro-1.10.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/avro-ipc-1.10.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/avro-mapred-1.10.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/blas-2.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n","spark-3.2.1-bin-hadoop3.2/jars/breeze-macros_2.12-1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/breeze_2.12-1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/cats-kernel_2.12-2.1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/chill-java-0.10.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/chill_2.12-0.10.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-cli-1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-codec-1.15.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-compress-1.21.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-crypto-1.1.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-io-2.8.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-lang-2.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-lang3-3.12.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-net-3.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/commons-text-1.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/core-1.1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n","spark-3.2.1-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n","spark-3.2.1-bin-hadoop3.2/jars/derby-10.14.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/generex-1.0.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/gson-2.2.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/guava-14.0.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-api-3.3.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-runtime-3.3.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hadoop-shaded-guava-1.1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.3.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-beeline-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-cli-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-common-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-exec-2.3.9-core.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-jdbc-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-llap-common-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-metastore-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-serde-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-service-rpc-3.1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-shims-0.23-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-shims-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-shims-common-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-storage-api-2.7.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.9.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n","spark-3.2.1-bin-hadoop3.2/jars/httpclient-4.5.13.jar\n","spark-3.2.1-bin-hadoop3.2/jars/httpcore-4.4.14.jar\n","spark-3.2.1-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-annotations-2.12.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-core-2.12.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-databind-2.12.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.12.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.11.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.12.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.servlet-api-4.0.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/janino-3.0.16.jar\n","spark-3.2.1-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n","spark-3.2.1-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/javolution-5.5.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-client-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-common-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-core-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-hk2-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jersey-server-2.34.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jline-2.14.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/joda-time-2.10.10.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jpam-1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/json-1.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/json4s-ast_2.12-3.7.0-M11.jar\n","spark-3.2.1-bin-hadoop3.2/jars/json4s-core_2.12-3.7.0-M11.jar\n","spark-3.2.1-bin-hadoop3.2/jars/json4s-jackson_2.12-3.7.0-M11.jar\n","spark-3.2.1-bin-hadoop3.2/jars/json4s-scalap_2.12-3.7.0-M11.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jta-1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-client-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-admissionregistration-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apiextensions-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apps-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-autoscaling-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-batch-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-certificates-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-common-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-coordination-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-core-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-discovery-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-events-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-extensions-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-flowcontrol-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-metrics-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-networking-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-node-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-policy-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-rbac-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-scheduling-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-storageclass-5.4.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/lapack-2.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/log4j-1.2.17.jar\n","spark-3.2.1-bin-hadoop3.2/jars/logging-interceptor-3.12.12.jar\n","spark-3.2.1-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n","spark-3.2.1-bin-hadoop3.2/jars/metrics-core-4.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/metrics-graphite-4.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/metrics-jmx-4.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/metrics-json-4.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/metrics-jvm-4.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/minlog-1.3.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/netty-all-4.1.68.Final.jar\n","spark-3.2.1-bin-hadoop3.2/jars/objenesis-2.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/okhttp-3.12.12.jar\n","spark-3.2.1-bin-hadoop3.2/jars/okio-1.14.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/opencsv-2.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/orc-core-1.6.12.jar\n","spark-3.2.1-bin-hadoop3.2/jars/orc-mapreduce-1.6.12.jar\n","spark-3.2.1-bin-hadoop3.2/jars/orc-shims-1.6.12.jar\n","spark-3.2.1-bin-hadoop3.2/jars/oro-2.0.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/paranamer-2.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-column-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-common-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-encoding-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-format-structures-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-hadoop-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/parquet-jackson-1.12.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/py4j-0.10.9.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/pyrolite-4.30.jar\n","spark-3.2.1-bin-hadoop3.2/jars/rocksdbjni-6.20.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-compiler-2.12.15.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-library-2.12.15.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-reflect-2.12.15.jar\n","spark-3.2.1-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n","spark-3.2.1-bin-hadoop3.2/jars/shims-0.9.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n","spark-3.2.1-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n","spark-3.2.1-bin-hadoop3.2/jars/snakeyaml-1.27.jar\n","spark-3.2.1-bin-hadoop3.2/jars/snappy-java-1.1.8.4.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-catalyst_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-core_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-graphx_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-hive_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-kvstore_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-launcher_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-mesos_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-mllib_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-network-common_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-repl_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-sketch_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-sql_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-streaming_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1-tests.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spark-yarn_2.12-3.2.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spire-util_2.12-0.17.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/spire_2.12-0.17.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/stream-2.9.6.jar\n","spark-3.2.1-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/tink-1.6.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/transaction-api-1.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/univocity-parsers-2.9.1.jar\n","spark-3.2.1-bin-hadoop3.2/jars/velocity-1.5.jar\n","spark-3.2.1-bin-hadoop3.2/jars/xbean-asm9-shaded-4.20.jar\n","spark-3.2.1-bin-hadoop3.2/jars/xz-1.8.jar\n","spark-3.2.1-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n","spark-3.2.1-bin-hadoop3.2/jars/zookeeper-3.6.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/zookeeper-jute-3.6.2.jar\n","spark-3.2.1-bin-hadoop3.2/jars/zstd-jni-1.5.0-4.jar\n","spark-3.2.1-bin-hadoop3.2/kubernetes/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n","spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/autoscale.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n","spark-3.2.1-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n","spark-3.2.1-bin-hadoop3.2/licenses/\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-blas.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-janino.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javassist.html\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jline.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-join.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-respond.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scala.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-spire.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n","spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n","spark-3.2.1-bin-hadoop3.2/python/\n","spark-3.2.1-bin-hadoop3.2/python/.coveragerc\n","spark-3.2.1-bin-hadoop3.2/python/.gitignore\n","spark-3.2.1-bin-hadoop3.2/python/MANIFEST.in\n","spark-3.2.1-bin-hadoop3.2/python/README.md\n","spark-3.2.1-bin-hadoop3.2/python/dist/\n","spark-3.2.1-bin-hadoop3.2/python/docs/\n","spark-3.2.1-bin-hadoop3.2/python/docs/Makefile\n","spark-3.2.1-bin-hadoop3.2/python/docs/make.bat\n","spark-3.2.1-bin-hadoop3.2/python/docs/make2.bat\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/copybutton.js\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/pyspark.css\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class_with_docs.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/conf.py\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/contributing.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/debugging.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/setting_ide.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/development/testing.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/install.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_df.ipynb\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_ps.ipynb\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/koalas_to_pyspark.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ml.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.mllib.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/extensions.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/frame.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/general_functions.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/groupby.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/indexing.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/io.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/ml.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/series.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/window.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.resource.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.sql.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ss.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.streaming.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/arrow_pandas.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/faq.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/options.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/types.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/python_packaging.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/arrow_pandas.rst\n","spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/index.rst\n","spark-3.2.1-bin-hadoop3.2/python/lib/\n","spark-3.2.1-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n","spark-3.2.1-bin-hadoop3.2/python/lib/py4j-0.10.9.3-src.zip\n","spark-3.2.1-bin-hadoop3.2/python/lib/pyspark.zip\n","spark-3.2.1-bin-hadoop3.2/python/mypy.ini\n","spark-3.2.1-bin-hadoop3.2/python/pylintrc\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/install.cpython-38.pyc\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/_globals.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/_typing.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle_fast.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/compat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/context.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/daemon.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/files.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/files.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/find_spark_home.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/install.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/java_gateway.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/join.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/_typing.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/_typing.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/_typing.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/accessors.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/categorical.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/config.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/binary_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/boolean_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/categorical_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/complex_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/date_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/datetime_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/null_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/num_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/string_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/udt_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/datetimes.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/exceptions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/extensions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/frame.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/generic.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/groupby.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/category.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/datetimes.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/multi.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/numeric.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexing.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/internal.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/common.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/frame.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/groupby.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/indexes.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/series.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/window.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/ml.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/mlflow.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/namespace.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/numpy_compat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/core.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/matplotlib.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/plotly.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/series.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/accessors.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/sql_processor.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/strings.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_base.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_category.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_datetime.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_categorical.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_config.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_csv.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_conversion.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_default_index.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_expanding.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_extension.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_frame_spark.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_groupby.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexing.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexops_spark.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_internal.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_namespace.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_numpy_compat.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_repr.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_reshape.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_rolling.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_conversion.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_datetime.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_string.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_spark_functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_sql.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_stats.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_typedef.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_window.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/string_typehints.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/typehints.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/usage_logger.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/window.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/py.typed\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/python/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/shell.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/rddsampler.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/test_resources.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/serializers.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/shell.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/shuffle.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/_typing.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/status.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/status.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/pandasutils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/__init__.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_context.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_install_spark.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_join.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/traceback_utils.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/util.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/util.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/version.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/version.pyi\n","spark-3.2.1-bin-hadoop3.2/python/pyspark/worker.py\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/PKG-INFO\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/SOURCES.txt\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/dependency_links.txt\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/requires.txt\n","spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/top_level.txt\n","spark-3.2.1-bin-hadoop3.2/python/run-tests\n","spark-3.2.1-bin-hadoop3.2/python/run-tests-with-coverage\n","spark-3.2.1-bin-hadoop3.2/python/run-tests.py\n","spark-3.2.1-bin-hadoop3.2/python/setup.cfg\n","spark-3.2.1-bin-hadoop3.2/python/setup.py\n","spark-3.2.1-bin-hadoop3.2/python/test_coverage/\n","spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/\n","spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n","spark-3.2.1-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n","spark-3.2.1-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n","spark-3.2.1-bin-hadoop3.2/python/test_support/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n","spark-3.2.1-bin-hadoop3.2/python/test_support/hello/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/hello/hello.txt\n","spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages.csv\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people.json\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people1.json\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array.json\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n","spark-3.2.1-bin-hadoop3.2/python/test_support/sql/text-test.txt\n","spark-3.2.1-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n","spark-3.2.1-bin-hadoop3.2/python/test_support/userlibrary.py\n","spark-3.2.1-bin-hadoop3.2/sbin/\n","spark-3.2.1-bin-hadoop3.2/sbin/decommission-slave.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/decommission-worker.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/slaves.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/spark-config.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/spark-daemon.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/spark-daemons.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-all.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-history-server.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-master.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-slave.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-slaves.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-thriftserver.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-worker.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/start-workers.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-all.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-history-server.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-master.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-slave.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-slaves.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-thriftserver.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-worker.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/stop-workers.sh\n","spark-3.2.1-bin-hadoop3.2/sbin/workers.sh\n","spark-3.2.1-bin-hadoop3.2/yarn/\n","spark-3.2.1-bin-hadoop3.2/yarn/spark-3.2.1-yarn-shuffle.jar\n"]}]},{"cell_type":"code","source":["## install requirement library for spark \n","!pip install -q findspark "],"metadata":{"id":"LvX0GLllnQXh","executionInfo":{"status":"ok","timestamp":1654261460947,"user_tz":-120,"elapsed":7038,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["## setting up location for spark and java home directory on drive\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""],"metadata":{"id":"BIUuUoOKnR3B","executionInfo":{"status":"ok","timestamp":1654261460948,"user_tz":-120,"elapsed":17,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## install pyspark\n","!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Icy6F47nWmh","outputId":"404df50c-be51-4a94-bc74-c9a90051b705","executionInfo":{"status":"ok","timestamp":1654261510906,"user_tz":-120,"elapsed":49971,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     || 281.4 MB 24 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     || 198 kB 59.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=7b250ba00cdb81036c1e7f94972ecb7ecefed2f728a7ddb5106db95de2422610\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}]},{"cell_type":"markdown","source":["# Prepare data"],"metadata":{"id":"JZR2w12ln1bM"}},{"cell_type":"markdown","source":["## Import necessary library "],"metadata":{"id":"EYyDgp_pegej"}},{"cell_type":"code","source":["## Normal libs to work with data\n","## adding support for large, multi-dimensional arrays and matrices.\n","import numpy as np \n","## data structures and operations for manipulating numerical tables and time series.\n","import pandas as pd \n","\n","################################################################################\n","# Visualization\n","## the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n","%matplotlib inline \n","## provides an implicit, MATLAB-like, way of plotting\n","import matplotlib.pyplot as plt \n","## provides a high-level interface for drawing attractive and informative statistical\n","import seaborn as sns\n","\n","################################################################################\n","## Utility\n","from collections import Counter\n","import string\n","\n","################################################################################\n","## Feature engineering\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.probability import FreqDist\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk import word_tokenize\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.feature import IDF\n","from pyspark.ml.feature import StopWordsRemover\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.ml.feature import Tokenizer\n","from pyspark.ml.feature import VectorAssembler\n","## utility packs for text processing, i.e. lower case all text\n","from pyspark.sql.functions import *\n","\n","\n","################################################################################\n","## ML models\n","## split data into train and test\n","from sklearn.model_selection import train_test_split\n","## use for classification pyspark models\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.classification import GBTClassifier\n","from pyspark.ml.classification import MultilayerPerceptronClassifier\n","from pyspark.ml.classification import LinearSVC\n","\n","################################################################################\n","## Evaluate model\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","import sklearn.metrics as metrics\n","## pyspark evaluation for classification models\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{"id":"0N695a8beyPe","executionInfo":{"status":"ok","timestamp":1654261512473,"user_tz":-120,"elapsed":1631,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import pyspark"],"metadata":{"id":"2VNXj9lYqlk8","executionInfo":{"status":"ok","timestamp":1654261513025,"user_tz":-120,"elapsed":20,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["pyspark.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"jVw1p4EWqoAP","executionInfo":{"status":"ok","timestamp":1654261513026,"user_tz":-120,"elapsed":18,"user":{"displayName":"Thien Huu","userId":"17344855178654932508"}},"outputId":"bf185ab1-9960-426c-f62f-467da651c3fc"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.2.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["## download external text libs data\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHYCfBcJoLgj","outputId":"1904e7c9-1814-49c6-c547-78182389cb8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## Get data"],"metadata":{"id":"pLToathFkFLl"}},{"cell_type":"code","source":["## get data from remote file if needed\n","## url = \"https://docs.google.com/spreadsheets/d/1ZVemCFQ_cWCEjriTFBLYHGM33q56eISk/edit?usp=sharing&ouid=102981063366545209715&rtpof=true&sd=true\"\n","## s = requests.get(url).text\n","\n","## get data by uploading file\n","df = pd.read_excel('Womens_Clothing_E_Commerce_Reviews.xlsx', sheet_name='Reviews', index_col=0)"],"metadata":{"id":"gmSyw5zPkFFP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## check 5 rows of dataset\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"82waGx8ckIzH","outputId":"0ca3dd98-8e4a-421a-9ed1-96f06634d611"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Clothing ID   Age                    Title  \\\n","0.0        767.0  33.0                      NaN   \n","1.0       1080.0  34.0                      NaN   \n","2.0       1077.0  60.0  Some major design flaws   \n","3.0       1049.0  50.0         My favorite buy!   \n","4.0        847.0  47.0         Flattering shirt   \n","\n","                                           Review Text  Rating  \\\n","0.0  Absolutely wonderful - silky and sexy and comf...     4.0   \n","1.0  Love this dress!  it's sooo pretty.  i happene...     5.0   \n","2.0  I had such high hopes for this dress and reall...     3.0   \n","3.0  I love, love, love this jumpsuit. it's fun, fl...     5.0   \n","4.0  This shirt is very flattering to all due to th...     5.0   \n","\n","     Recommended IND  Positive Feedback Count   Division Name Department Name  \\\n","0.0              1.0                      0.0       Initmates        Intimate   \n","1.0              1.0                      4.0         General         Dresses   \n","2.0              0.0                      0.0         General         Dresses   \n","3.0              1.0                      0.0  General Petite         Bottoms   \n","4.0              1.0                      6.0         General            Tops   \n","\n","    Class Name  \n","0.0  Intimates  \n","1.0    Dresses  \n","2.0    Dresses  \n","3.0      Pants  \n","4.0    Blouses  "],"text/html":["\n","  <div id=\"df-f691ea0a-b8d2-45b3-9c52-21c9d052886c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>767.0</td>\n","      <td>33.0</td>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Initmates</td>\n","      <td>Intimate</td>\n","      <td>Intimates</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>1080.0</td>\n","      <td>34.0</td>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1077.0</td>\n","      <td>60.0</td>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1049.0</td>\n","      <td>50.0</td>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>General Petite</td>\n","      <td>Bottoms</td>\n","      <td>Pants</td>\n","    </tr>\n","    <tr>\n","      <th>4.0</th>\n","      <td>847.0</td>\n","      <td>47.0</td>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>General</td>\n","      <td>Tops</td>\n","      <td>Blouses</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f691ea0a-b8d2-45b3-9c52-21c9d052886c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f691ea0a-b8d2-45b3-9c52-21c9d052886c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f691ea0a-b8d2-45b3-9c52-21c9d052886c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Feature engineering"],"metadata":{"id":"ae78PepKiP3i"}},{"cell_type":"markdown","source":["#### Fill NaN value with ' '. Avoid nan string when combine texts"],"metadata":{"id":"kfgeTqfvj7BF"}},{"cell_type":"code","source":["## avoid nan string when combine texts\n","df['Title'] = df['Title'].fillna('')\n","df['Review Text'] = df['Review Text'].fillna('')"],"metadata":{"id":"5Lq78UHcj63I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Combine Title & Review Text column into 1 Review Description column"],"metadata":{"id":"unIg5V6Aj2tX"}},{"cell_type":"code","source":["## combine Title & Review Text column into 1 Review Description column\n","df = df.assign(ReviewDescription = df['Title'].astype(str) + ' ' + df['Review Text'].astype(str))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659},"id":"cjI_kwmqj3GB","outputId":"c3509e13-f4a4-4222-8050-44145a0e95d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Clothing ID   Age                    Title  \\\n","0.0        767.0  33.0                            \n","1.0       1080.0  34.0                            \n","2.0       1077.0  60.0  Some major design flaws   \n","3.0       1049.0  50.0         My favorite buy!   \n","4.0        847.0  47.0         Flattering shirt   \n","\n","                                           Review Text  Rating  \\\n","0.0  Absolutely wonderful - silky and sexy and comf...     4.0   \n","1.0  Love this dress!  it's sooo pretty.  i happene...     5.0   \n","2.0  I had such high hopes for this dress and reall...     3.0   \n","3.0  I love, love, love this jumpsuit. it's fun, fl...     5.0   \n","4.0  This shirt is very flattering to all due to th...     5.0   \n","\n","     Recommended IND  Positive Feedback Count   Division Name Department Name  \\\n","0.0              1.0                      0.0       Initmates        Intimate   \n","1.0              1.0                      4.0         General         Dresses   \n","2.0              0.0                      0.0         General         Dresses   \n","3.0              1.0                      0.0  General Petite         Bottoms   \n","4.0              1.0                      6.0         General            Tops   \n","\n","    Class Name                                  ReviewDescription  \n","0.0  Intimates   Absolutely wonderful - silky and sexy and com...  \n","1.0    Dresses   Love this dress!  it's sooo pretty.  i happen...  \n","2.0    Dresses  Some major design flaws I had such high hopes ...  \n","3.0      Pants  My favorite buy! I love, love, love this jumps...  \n","4.0    Blouses  Flattering shirt This shirt is very flattering...  "],"text/html":["\n","  <div id=\"df-ceaaf259-3ad4-4d61-876d-b3249c61ff53\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","      <th>ReviewDescription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>767.0</td>\n","      <td>33.0</td>\n","      <td></td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Initmates</td>\n","      <td>Intimate</td>\n","      <td>Intimates</td>\n","      <td>Absolutely wonderful - silky and sexy and com...</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>1080.0</td>\n","      <td>34.0</td>\n","      <td></td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1077.0</td>\n","      <td>60.0</td>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Some major design flaws I had such high hopes ...</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1049.0</td>\n","      <td>50.0</td>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>General Petite</td>\n","      <td>Bottoms</td>\n","      <td>Pants</td>\n","      <td>My favorite buy! I love, love, love this jumps...</td>\n","    </tr>\n","    <tr>\n","      <th>4.0</th>\n","      <td>847.0</td>\n","      <td>47.0</td>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>General</td>\n","      <td>Tops</td>\n","      <td>Blouses</td>\n","      <td>Flattering shirt This shirt is very flattering...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceaaf259-3ad4-4d61-876d-b3249c61ff53')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ceaaf259-3ad4-4d61-876d-b3249c61ff53 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ceaaf259-3ad4-4d61-876d-b3249c61ff53');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#### Drop NaN values"],"metadata":{"id":"596-A0hljuFv"}},{"cell_type":"code","source":["## drop NaN values in categorical columns\n","df = df.dropna()\n","df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J86ro357jt3G","outputId":"91aad525-0b28-46f7-c917-e730f3afd982"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Clothing ID                0\n","Age                        0\n","Title                      0\n","Review Text                0\n","Rating                     0\n","Recommended IND            0\n","Positive Feedback Count    0\n","Division Name              0\n","Department Name            0\n","Class Name                 0\n","ReviewDescription          0\n","dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["#### Remove special character in ReviewDescription column"],"metadata":{"id":"WogvSzWBjuc2"}},{"cell_type":"code","source":["## remove special character\n","df['ReviewDescription'] = df['ReviewDescription'].str.replace(r\"[^a-zA-Z ]\",\"\")\n","df['ReviewDescription'] = df['ReviewDescription'].str.replace(r\"[0-9]\",\"\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"id":"H4feTf87jpDl","outputId":"d52d5078-c83b-4213-deab-2fd3b757182b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"execute_result","data":{"text/plain":["     Clothing ID   Age                    Title  \\\n","0.0        767.0  33.0                            \n","1.0       1080.0  34.0                            \n","2.0       1077.0  60.0  Some major design flaws   \n","3.0       1049.0  50.0         My favorite buy!   \n","4.0        847.0  47.0         Flattering shirt   \n","\n","                                           Review Text  Rating  \\\n","0.0  Absolutely wonderful - silky and sexy and comf...     4.0   \n","1.0  Love this dress!  it's sooo pretty.  i happene...     5.0   \n","2.0  I had such high hopes for this dress and reall...     3.0   \n","3.0  I love, love, love this jumpsuit. it's fun, fl...     5.0   \n","4.0  This shirt is very flattering to all due to th...     5.0   \n","\n","     Recommended IND  Positive Feedback Count   Division Name Department Name  \\\n","0.0              1.0                      0.0       Initmates        Intimate   \n","1.0              1.0                      4.0         General         Dresses   \n","2.0              0.0                      0.0         General         Dresses   \n","3.0              1.0                      0.0  General Petite         Bottoms   \n","4.0              1.0                      6.0         General            Tops   \n","\n","    Class Name                                  ReviewDescription  \n","0.0  Intimates   Absolutely wonderful  silky and sexy and comf...  \n","1.0    Dresses   Love this dress  its sooo pretty  i happened ...  \n","2.0    Dresses  Some major design flaws I had such high hopes ...  \n","3.0      Pants  My favorite buy I love love love this jumpsuit...  \n","4.0    Blouses  Flattering shirt This shirt is very flattering...  "],"text/html":["\n","  <div id=\"df-05dcf440-3ebb-4eef-b5cd-dd0efa6e53b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","      <th>ReviewDescription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>767.0</td>\n","      <td>33.0</td>\n","      <td></td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Initmates</td>\n","      <td>Intimate</td>\n","      <td>Intimates</td>\n","      <td>Absolutely wonderful  silky and sexy and comf...</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>1080.0</td>\n","      <td>34.0</td>\n","      <td></td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Love this dress  its sooo pretty  i happened ...</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1077.0</td>\n","      <td>60.0</td>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Some major design flaws I had such high hopes ...</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1049.0</td>\n","      <td>50.0</td>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>General Petite</td>\n","      <td>Bottoms</td>\n","      <td>Pants</td>\n","      <td>My favorite buy I love love love this jumpsuit...</td>\n","    </tr>\n","    <tr>\n","      <th>4.0</th>\n","      <td>847.0</td>\n","      <td>47.0</td>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>General</td>\n","      <td>Tops</td>\n","      <td>Blouses</td>\n","      <td>Flattering shirt This shirt is very flattering...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05dcf440-3ebb-4eef-b5cd-dd0efa6e53b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-05dcf440-3ebb-4eef-b5cd-dd0efa6e53b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-05dcf440-3ebb-4eef-b5cd-dd0efa6e53b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["#### Binning rating"],"metadata":{"id":"4_blkUkFjqsB"}},{"cell_type":"code","source":["## if 1-3 stars = 0 \n","## if 4-5 stars = 1\n","bins = [0, 3, 5]\n","labels = [0,1]\n","df['Binned Rating'] = pd.cut(df['Rating'], bins=bins, labels=labels)\n","df.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":778},"id":"qF-oD0zvjmca","outputId":"10e30c66-5a44-4b8f-a11f-1800b95fe621"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Clothing ID   Age                                              Title  \\\n","23476.0       1104.0  34.0                     Great dress for many occasions   \n","23477.0        862.0  48.0                         Wish it was made of cotton   \n","23478.0       1104.0  31.0                              Cute, but see through   \n","23479.0       1084.0  28.0  Very cute dress, perfect for summer parties an...   \n","23480.0       1104.0  52.0                    Please make more like this one!   \n","\n","                                               Review Text  Rating  \\\n","23476.0  I was very happy to snag this dress at such a ...     5.0   \n","23477.0  It reminds me of maternity clothes. soft, stre...     3.0   \n","23478.0  This fit well, but the top was very see throug...     3.0   \n","23479.0  I bought this dress for a wedding i have this ...     3.0   \n","23480.0  This dress in a lovely platinum is feminine an...     5.0   \n","\n","         Recommended IND  Positive Feedback Count   Division Name  \\\n","23476.0              1.0                      0.0  General Petite   \n","23477.0              1.0                      0.0  General Petite   \n","23478.0              0.0                      1.0  General Petite   \n","23479.0              1.0                      2.0         General   \n","23480.0              1.0                     22.0  General Petite   \n","\n","        Department Name Class Name  \\\n","23476.0         Dresses    Dresses   \n","23477.0            Tops      Knits   \n","23478.0         Dresses    Dresses   \n","23479.0         Dresses    Dresses   \n","23480.0         Dresses    Dresses   \n","\n","                                         ReviewDescription Binned Rating  \n","23476.0  Great dress for many occasions I was very happ...             1  \n","23477.0  Wish it was made of cotton It reminds me of ma...             0  \n","23478.0  Cute but see through This fit well but the top...             0  \n","23479.0  Very cute dress perfect for summer parties and...             0  \n","23480.0  Please make more like this one This dress in a...             1  "],"text/html":["\n","  <div id=\"df-e783ebd8-8018-4504-9e47-d62684ef5856\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","      <th>ReviewDescription</th>\n","      <th>Binned Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23476.0</th>\n","      <td>1104.0</td>\n","      <td>34.0</td>\n","      <td>Great dress for many occasions</td>\n","      <td>I was very happy to snag this dress at such a ...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>General Petite</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Great dress for many occasions I was very happ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23477.0</th>\n","      <td>862.0</td>\n","      <td>48.0</td>\n","      <td>Wish it was made of cotton</td>\n","      <td>It reminds me of maternity clothes. soft, stre...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>General Petite</td>\n","      <td>Tops</td>\n","      <td>Knits</td>\n","      <td>Wish it was made of cotton It reminds me of ma...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23478.0</th>\n","      <td>1104.0</td>\n","      <td>31.0</td>\n","      <td>Cute, but see through</td>\n","      <td>This fit well, but the top was very see throug...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>General Petite</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Cute but see through This fit well but the top...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23479.0</th>\n","      <td>1084.0</td>\n","      <td>28.0</td>\n","      <td>Very cute dress, perfect for summer parties an...</td>\n","      <td>I bought this dress for a wedding i have this ...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Very cute dress perfect for summer parties and...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23480.0</th>\n","      <td>1104.0</td>\n","      <td>52.0</td>\n","      <td>Please make more like this one!</td>\n","      <td>This dress in a lovely platinum is feminine an...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>22.0</td>\n","      <td>General Petite</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","      <td>Please make more like this one This dress in a...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e783ebd8-8018-4504-9e47-d62684ef5856')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e783ebd8-8018-4504-9e47-d62684ef5856 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e783ebd8-8018-4504-9e47-d62684ef5856');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["#### Copy df"],"metadata":{"id":"pyNsaR-jbQ9p"}},{"cell_type":"code","source":["## copy df into another dataframe to save original data\n","rating_class = df.copy()"],"metadata":{"id":"r4-PXCiNbPjB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Remove unfrequent words"],"metadata":{"id":"NtWxHP0wnsX2"}},{"cell_type":"code","source":["## get a frequent word dictionary\n","words_fdist = FreqDist(word for word in word_tokenize(rating_class['ReviewDescription'].str.cat(sep=' ')))\n","\n","## convert dict to df\n","words_df = pd.DataFrame.from_dict(words_fdist,\\\n","                                       orient='index').\\\n","                                rename(columns={0:'freq'})\n","\n","## get common list words                                \n","common_l = words_df[words_df.freq > 50].index.to_list()\n","print(common_l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uULxx2f4jFyF","outputId":"7d0c8736-d63c-4fc6-9fef-b454751ab33a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Absolutely', 'wonderful', 'silky', 'and', 'sexy', 'comfortable', 'Love', 'this', 'dress', 'its', 'pretty', 'i', 'happened', 'to', 'find', 'it', 'in', 'a', 'store', 'im', 'glad', 'did', 'bc', 'never', 'would', 'have', 'ordered', 'online', 'petite', 'bought', 'am', 'love', 'the', 'length', 'on', 'me', 'hits', 'just', 'little', 'below', 'knee', 'definitely', 'be', 'true', 'midi', 'someone', 'who', 'is', 'truly', 'design', 'flaws', 'I', 'had', 'such', 'high', 'hopes', 'for', 'really', 'wanted', 'work', 'initially', 'small', 'my', 'usual', 'size', 'but', 'found', 'so', 'fact', 'that', 'could', 'not', 'zip', 'up', 'medium', 'which', 'was', 'ok', 'overall', 'top', 'half', 'fit', 'nicely', 'bottom', 'very', 'tight', 'under', 'layer', 'several', 'somewhat', 'cheap', 'over', 'layers', 'flaw', 'sewn', 'into', 'zipper', 'c', 'My', 'favorite', 'buy', 'jumpsuit', 'fun', 'flirty', 'fabulous', 'every', 'time', 'wear', 'get', 'nothing', 'great', 'compliments', 'Flattering', 'shirt', 'This', 'flattering', 'all', 'due', 'adjustable', 'front', 'tie', 'perfect', 'with', 'leggings', 'sleeveless', 'pairs', 'well', 'any', 'cardigan', 'Not', 'dresses', 'one', 'feet', 'tall', 'usually', 'p', 'brand', 'out', 'of', 'package', 'lot', 'skirt', 'long', 'full', 'frame', 'take', 'away', 'from', 'garment', 'color', 'idea', 'style', 'returned', 'at', 'hte', 'last', 'see', 'what', 'look', 'like', 'person', 'pick', 'went', 'only', 'because', 'pale', 'gorgeous', 'trying', 'baggy', 'xs', 'bummer', 'no', 'decided', 'though', 'as', 'said', 'everything', 'pants', 'skirts', 'kept', 'surprisingly', 'goes', 'lots', 'ton', 'always', 'try', 'used', 'pair', 'nice', 'pencil', 'flare', 'etc', 'bit', 'big', 'sleeves', 'are', 'doesnt', 'go', 'also', 'loose', 'xxs', 'later', 'since', 'light', 'already', 'sold', 'an', 'runs', 'snug', 'bust', 'feminine', 'retailer', 'flair', 'Such', 'Im', 'lbs', 's', 'make', 'sure', 'wasnt', 'too', 'typically', 'regular', 'if', 'youre', 'less', 'busty', 'b', 'cup', 'or', 'smaller', 'will', 'you', 'perfectly', 'party', 'down', 'longer', 'then', 'fabric', 'underneath', 'perfection', 'Perfect', 'more', 'myself', 'reviews', 'by', 'before', 'most', 'past', 'they', 'right', 'their', 'product', 'case', 'been', 'even', 'tried', 'beautifully', 'made', 'lined', 'old', 'quality', 'solid', 'outer', 'print', 'tts', 'falls', 'above', 'does', 'Runs', 'Bought', 'black', 'didnt', 'bother', 'lining', 'portion', 'around', 'chest', 'flowy', 'lower', 'say', 'running', 'straps', 'easily', 'came', 'knees', 'Pretty', 'some', 'issues', 'choice', 'holiday', 'enough', 'office', 'opinion', 'those', 'larger', 'perhaps', 'waist', 'problem', 'fabrics', 'terrible', 'delicate', 'type', 'got', 'stuck', 'Nice', 'body', 'took', 'these', 'them', 'tell', 'put', 'wouldnt', 'hourglass', 'figure', 'straight', 'way', 'shape', 'sized', 'still', 'roomy', 'hips', 'sturdy', 'hope', 'happy', 'need', 'least', 'average', 'height', 'taller', 'leg', 'opening', 'large', 'ankle', 'hem', 'line', 'pleats', 'think', 'can', 'imagine', 'may', 'good', 'Looks', 'white', 'chance', 'blouse', 'crazy', 'about', 'how', 'model', 'paired', 'worked', 'crisp', 'clean', 'fits', 'drape', 'tucked', 'cant', 'wrong', 'Super', 'cute', 'cozy', 'A', 'super', 'coat', 'cold', 'dry', 'days', 'jeans', 'dressier', 'outfit', 'Stylish', 'feel', 'looking', 'something', 'different', 'new', 'years', 'chested', 'form', 'fitting', 'once', 'xsp', 'Cute', 'If', 'tailor', 'do', 'simple', 'fix', 'lb', 'pregnant', 't', 'back', 'price', 'thought', 'embroidered', 'when', 'opened', 'box', 'tad', 'tiny', 'vibrant', 'unique', 'keep', 'going', 'although', 'there', 'except', 'wish', 'were', 'looks', 'First', 'pullover', 'styling', 'side', 'purchased', 'knew', 'next', 'feels', 'slip', 'has', 'awkward', 'described', 'sadly', 'returning', 'exchange', 'Like', 'dont', 'waisted', 'appears', 'pictured', 'Versatile', 'first', 'saw', 'seethrough', 'wore', 'wedges', 'vest', 'careful', 'buttons', 'havent', 'fall', 'off', 'yet', 'occasion', 'flat', 'Loved', 'material', 'both', 'much', 'wider', 'than', 'felt', 'fell', 'med', 'better', 'd', 'Huge', 'disappointment', 'waiting', 'sweater', 'weeks', 'excited', 'short', 'wide', 'weight', 'three', 'inches', 'nicer', 'looked', 'The', 'colors', 'werent', 'expected', 'either', 'dark', 'blue', 'couldnt', 'anything', 'thick', 'movement', 'end', 'Great', 'shirts', 'many', 'especially', 'says', 'wont', 'layering', 'piece', 'comfy', 'classic', 'beautiful', 'practical', 'cropped', 'boxy', 'part', 'others', 'mentioned', 'knit', 'makes', 'having', 'camisole', 'showing', 'wearing', 'warm', 'thin', 'jacket', 'trend', 'flared', 'crop', 'cuter', 'given', 'second', 'stripes', 'brighter', 'run', 'carry', 'belly', 'navy', 'blazer', 'These', 'downside', 'months', 'ago', 'finally', 'order', 'huge', 'issue', 'wool', 'else', 'guess', 'call', 'literally', 'itchy', 'sale', 'worth', 'paid', 'soft', 'added', 'bonus', 'needs', 'funky', 'tank', 'boots', 'Lovely', 'whim', 'seasons', 'while', 'tops', 'cut', 'lightweight', 'Just', 'mom', 'draped', 'ill', 'winter', 'polished', 'amazing', 'skinny', 'we', 'gray', 'photos', 'pull', 'sizing', 'accurate', 'stretch', 'casual', 'grey', 'pilcro', 'peplum', 'shoulders', 'neckline', 'worn', 'slacks', 'heels', 'embroidery', 'lovely', 'across', 'baby', 'year', 'why', 'again', 'Soft', 'poncho', 'plaid', 'check', 'cream', 'turtleneck', 'roll', 'spring', 'things', 'should', 'know', 'expect', 'sheer', 'considering', 'might', 'walk', 'house', 'oversized', 'pounds', 'want', 'along', 'being', 'stretched', 'mind', 'shows', 'colorful', 'Beautiful', 'Tried', 'today', 'local', 'bad', 'picture', 'alternative', 'plain', 'tee', 'generally', 'probably', 'two', 'tone', 'item', 'mine', 'seemed', 'started', 'id', 'recommend', 'Very', 'Really', 'collar', 'received', 'where', 'rather', 'wouldve', 'adorable', 'transition', 'summer', 'purchase', 'washed', 'best', 'likely', 'absolutely', 'm', 'unusual', 'asymmetrical', 'seam', 'detail', 'attached', 'actually', 'interest', 'adds', 'helps', 'hide', 'cowl', 'neck', 'done', 'ive', 'means', 'wardrobe', 'extremely', 'prints', 'wash', 'sleep', 'bra', 'okay', 'support', 'without', 'seen', 'passed', 'however', 'return', 'thats', 'ladies', 'loved', 'ruffle', 'o', 'altered', 'flats', 'plenty', 'floor', 'personally', 'elastic', 'waistband', 'belt', 'sits', 'tricky', 'sort', 'th', 'Ive', 'night', 'lines', 'tag', 'Gorgeous', 'simply', 'stunning', 'wait', 'happier', 'thread', 'left', 'behind', 'flimsy', 'gives', 'lounging', 'recently', 'after', 'torso', 'pattern', 'floral', 'springsummer', 'pilling', 'other', 'arent', 'mail', 'l', 'sometimes', 'xl', 'stretchy', 'lace', 'similar', 'tshirt', 'almost', 'gotten', 'extra', 'eyeing', 'works', 'sizes', 'give', 'goto', 'season', 'higher', 'must', 'difficult', 'button', 'your', 'unfortunately', 'strange', 'stay', 'weird', 'minute', 'pockets', 'shaped', 'pictures', 'hung', 'natural', 'thinking', 'she', 'sides', 'swing', 'making', 'anyone', 'between', 'bigger', 'cami', 'show', 'theres', 'fitted', 'uncomfortable', 'hang', 'another', 'reviewer', 'business', 'tailored', 'jewelry', 'times', 'surprised', 'hanger', 'difference', 'fan', 'dressed', 'cardi', 'believe', 'drawn', 'immediately', 'whole', 'read', 'comments', 'same', 'description', 'recommended', 'weigh', 'chose', 'disappointing', 'come', 'luxurious', 'obsessed', 'everyday', 'wears', 'drapey', 'arms', 'So', 'normal', 'fine', 'gets', 'bring', 'alone', 'originally', 'petites', 'hit', 'hemmed', 'hair', 'elegant', 'stylish', 'grab', 'plan', 'rest', 'reviewers', 'orange', 'brown', 'colored', 'jackets', 'bulky', 'heavy', 'appropriate', 'day', 'option', 'v', 'week', 'snaps', 'ways', 'through', 'touch', 'typical', 'concern', 'holes', 'washes', 'water', 'hopefully', 'slits', 'hoping', 'looser', 'photo', 'weave', 'deep', 'olive', 'section', 'room', 'neutral', 'spot', 'decide', 'dd', 'velvet', 'tunic', 'instead', 'linen', 'wellmade', 'quite', 'curvy', 'now', 'prettier', 'real', 'life', 'texture', 'modern', 'otherwise', 'versatile', 'caught', 'eye', 'far', 'shorts', 'prefer', 'items', 'versatility', 'outfits', 'fence', 'seriously', 'Purchased', 'liked', 'green', 'fantastic', 'f', 'tent', 'daughter', 'red', 'shapeless', 'easy', 'mostly', 'exactly', 'slightly', 'near', 'upper', 'throughout', 'Comfy', 'lean', 'forward', 'Simple', 'despite', 'hides', 'scoop', 'Stunning', 'constructed', 'reference', 'measurements', 'unflattering', 'teal', 'disappointed', 'darker', 'beauty', 'drapes', 'comes', 'gave', 'stars', 'ivory', 'inside', 'cuffs', 'keeping', 'normally', 'hot', 'weather', 'Poor', 'poor', 'plus', 'coming', 'review', 'totally', 'disagree', 'generous', 'necklace', 'broad', 'few', 'hours', 'Disappointing', 'faded', 'area', 'stiff', 'please', 'send', 'clothing', 'vintage', 'pulled', 'funny', 'narrow', 'strapless', 'Cozy', 'subtle', 'turned', 'striped', 'each', 'tied', 'closet', 'round', 'wrinkle', 'hour', 'thing', 'note', 'After', 'reading', 'previous', 'hip', 'poorly', 'designed', 'gals', 'here', 'certainly', 'girls', 'places', 'ties', 'stand', 'hoped', 'let', 'interesting', 'expecting', 'needed', 'keeps', 'unless', 'hangs', 'odd', 'sleeve', 'machine', 'dryer', 'shrink', 'yes', 'cover', 'use', 'wonderfully', 'comfort', 'Its', 'wow', 'basically', 'tummy', 'construction', 'liner', 'vneck', 'doing', 'negative', 'point', 'In', 'seems', 'hard', 'closed', 'add', 'cotton', 'details', 'staple', 'star', 'shrunk', 'ones', 'itself', 'maybe', 'thicker', 'silhouette', 'pieces', 'styled', 'denim', 'layered', 'pink', 'scratchy', 'called', 'shoulder', 'her', 'kind', 'lady', 'built', 'able', 'winner', 'compared', 'during', 'course', 'noted', 'pics', 'justice', 'rich', 'impressed', 'shown', 'metallic', 'modest', 'change', 'figured', 'woman', 'low', 'agree', 'skin', 'multiple', 'match', 'mention', 'suit', 'us', 'ended', 'buying', 'dinner', 'based', 'ran', 'six', 'cleavage', 'sad', 'flares', 'leather', 'combination', 'materials', 'positive', 'ordering', 'realized', 'strap', 'coverup', 'anyway', 'w', 'plum', 'tighter', 'unlike', 'apart', 'notice', 'until', 'inch', 'bright', 'maeve', 'exception', 'pleasantly', 'upon', 'coverage', 'aline', 'flatter', 'types', 'Fun', 'band', 'romper', 'weekend', 'friends', 'legs', 'evening', 'breezy', 'thru', 'thank', 'Wonderful', 'pear', 'thinner', 'our', 'armholes', 'sweatshirt', 'getting', 'sweaters', 'sack', 'waistline', 'curves', 'closure', 'warmer', 'middle', 'depending', 'structure', 'lost', 'flowers', 'shorter', 'pay', 'cooler', 'live', 'threads', 'Size', 'purchases', 'xxsp', 'appear', 'slimmer', 'heavier', 'Fits', 'worried', 'gone', 'shame', 'snap', 'fallwinter', 'bohemian', 'snagged', 'edges', 'sz', 'washable', 'complaint', 'whether', 'ultimately', 'effect', 'special', 'Dress', 'people', 'statement', 'For', 'open', 'swimming', 'cost', 'snag', 'quickly', 'allows', 'scarf', 'Too', 'place', 'discount', 'softness', 'amount', 'overwhelming', 'stated', 'peach', 'isnt', 'dye', 'shade', 'women', 'dressy', 'couple', 'Classic', 'surprise', 'structured', 'yellow', 'designs', 'detailed', 'hook', 'cuff', 'bodice', 'fully', 'barely', 'butt', 'stick', 'pass', 'Adorable', 'jean', 'pic', 'blend', 'ruffles', 'hanging', 'care', 'keeper', 'styles', 'slim', 'forgiving', 'sandals', 'worry', 'age', 'Easy', 'throw', 'noticed', 'inseam', 'event', 'job', 'coloring', 'pant', 'airy', 'overly', 'wrinkled', 'slimming', 'blouses', 'heel', 'thighs', 'close', 'athletic', 'addition', 'lighter', 'help', 'flowing', 'realize', 'rise', 'mother', 'particular', 'muscular', 'exchanging', 'receive', 'Comfortable', 'feeling', 'beading', 'proportions', 'against', 'Ordered', 'twice', 'moment', 'bummed', 'washing', 'instructions', 'everywhere', 'holding', 'own', 'theyre', 'bottoms', 'combo', 'gold', 'substantial', 'xsmall', 'number', 'seem', 'stripe', 'shoes', 'highly', 'zipped', 'trouble', 'maternity', 'bunch', 'hesitant', 'stock', 'Amazing', 'planning', 'hold', 'sales', 'girl', 'taken', 'regret', 'jersey', 'stitching', 'parts', 'polka', 'tons', 'softer', 'edge', 'hugs', 'chic', 'cloth', 'stone', 'flannel', 'maxi', 'wedding', 'ever', 'lays', 'sloppy', 'missing', 'matter', 'shipping', 'lose', 'thrilled', 'dots', 'reason', 'rolled', 'leave', 'comfortably', 'trip', 'possible', 'flows', 'ankles', 'searching', 'lately', 'clothes', 'Best', 'yesterday', 'bell', 'arm', 'tanks', 'start', 'finding', 'hole', 'soon', 'version', 'youd', 'fairly', 'nude', 'stop', 'expectations', 'incredibly', 'outside', 'awesome', 'tend', 'sweet', 'busted', 'slender', 'supposed', 'slit', 'flow', 'sit', 'waste', 'tuck', 'seams', 'Better', 'currently', 'anywhere', 'closer', 'motif', 'cool', 'potential', 'retailers', 'wrinkles', 'tees', 'options', 'noticeable', 'picked', 'hand', 'available', 'When', 'basic', 'move', 'width', 'patterns', 'smooth', 'timeless', 'billowy', 'somehow', 'revealing', 'set', 'helped', 'putting', 'bulk', 'instore', 'rose', 'arrived', 'areas', 'problems', 'four', 'polyester', 'oh', 'wine', 'pricey', 'consider', 'warmth', 'adding', 'oddly', 'vibe', 'clingy', 'romantic', 'xss', 'build', 'fashion', 'excellent', 'lounge', 'trendy', 'accessories', 'Disappointed', 'mid', 'shot', 'post', 'seeing', 'detailing', 'robe', 'rib', 'exchanged', 'bag', 'completely', 'hemline', 'booties', 'husband', 'formal', 'gap', 'thigh', 'walked', 'classy', 'rough', 'christmas', 'he', 'dream', 'mean', 'covered', 'thanks', 'dressing', 'mustard', 'yoga', 'held', 'site', 'colder', 'holds', 'slight', 'shift', 'joggers', 'boho', 'stomach', 'appreciate', 'often', 'air', 'properly', 'relaxed', 'silk', 'attention', 'volume', 'concerned', 'waited', 'mix', 'placed', 'models', 'deal', 'disappoint', 'boyfriend', 'mixed', 'reminds', 'inner', 'asked', 'brands', 'faux', 'peasant', 'together', 'empire', 'bill', 'concept', 'bow', 'matching', 'placement', 'Awesome', 'Saw', 'sent', 'owned', 'coral', 'midsection', 'preferred', 'tan', 'adore', 'Good', 'meant', 'casually', 'gift', 'tights', 'double', 'avoid', 'honestly', 'blousy', 'pleased', 'home', 'showed', 'Wow', 'glove', 'considered', 'correct', 'ft', 'particularly', 'holidays', 'fur', 'burgundy', 'turquoise', 'early', 'Unique', 'sophisticated', 'ddd', 'cling', 'nearly', 'taking', 'transitional', 'head', 'complements', 'taupe', 'Wanted', 'spend', 'standard', 'It', 'beach', 'bathing', 'shopping', 'pop', 'suits', 'chambray', 'What', 'everyone', 'crotch', 'rayon', 'swimsuit', 'functional', 'lay', 'ml', 'cashmere', 'working', 'events', 'grabbed', 'Fabulous', 'boobs', 'itll', 'bum', 'trousers', 'moss', 'become', 'write', 'entire', 'catalog', 'travel', 'voluminous', 'wrap', 'slouchy', 'vacation', 'fuller', 'ridiculous', 'pulls', 'hug', 'taste', 'resist', 'expensive', 'florida', 'heat', 'exposed', 'falling', 'stores', 'frumpy', 'retro', 'beige', 'twist', 'additional', 'wearable', 'youll', 'breathable', 'flatters', 'understand', 'website', 'covers', 'month', 'yarn', 'money', 'rear', 'attractive', 'As', 'muted', 'suggest', 'beware', 'require', 'using', 'aware', 'ripped', 'professional', 'hate', 'feature', 'late', 'beyond', 'purple', 'awful', 'purchasing', 'summery', 'swingy', 'Got', 'cords', 'actual', 'takes', 'chinos', 'penny', 'ag', 'pocket', 'trim', 'silver', 'afraid', 'chunky', 'sending', 'miss', 'loves', 'occasions', 'Another', 'gaping', 'background', 'unlined', 'buttoned', 'center', 'saying', 'birthday', 'flower', 'legging', 'sm', 'giving', 'boring', 'designer', 'free', 'breaker', 'errands', 'lavender', 'cups', 'kimono', 'fair', 'rack', 'instantly', 'contrast', 'single', 'pulling', 'spots', 'possibly', 'darling', 'dried', 'visible', 'pajamas', 'horrible', 'date', 'sitting', 'art', 'offered', 'fringe', 'level', 'socks']\n"]}]},{"cell_type":"code","source":["## print number of common words\n","len(common_l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKQKIyHQjDpp","outputId":"472e954e-d929-40a4-8709-5edc0b146630"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1612"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["def remove_unfreq_words(review, common_l):\n","    ## tokenizer\n","    nopunc = []\n","    word_lst = []\n","    for word in review.split():\n","        if word.lower() not in common_l:\n","            review.replace(word, '')\n","        else:\n","            nopunc.append(word.lower()) ## lower text\n","\n","    nopunc = ' '.join(nopunc)\n","\n","    return nopunc"],"metadata":{"id":"moZBCIBtjCG5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## remove unfrequen words\n","rating_class['ReviewDescription'] = rating_class['ReviewDescription'].apply(remove_unfreq_words, common_l=common_l)\n","rating_class['ReviewDescription']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIBtEjXEi-ey","outputId":"6cc2dbea-259e-4281-bb7b-49928c0839c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0        absolutely wonderful silky and sexy and comfor...\n","1.0        love this dress its pretty i happened to find ...\n","2.0        some design flaws i had such high hopes for th...\n","3.0        my favorite buy i love love love this jumpsuit...\n","4.0        flattering shirt this shirt is very flattering...\n","                                 ...                        \n","23476.0    great dress for many occasions i was very happ...\n","23477.0    wish it was made of cotton it reminds me of ma...\n","23478.0    cute but see through this fit well but the top...\n","23479.0    very cute dress perfect for summer and we i bo...\n","23480.0    please make more like this one this dress in a...\n","Name: ReviewDescription, Length: 23467, dtype: object"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Init Spark"],"metadata":{"id":"Z-h8Gdmkm6l7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"arX_L9gvmVWo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0428aad4-256c-4a1f-aeb2-e57f6516788f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Init Spark successfully!\n"]}],"source":["def init_spark(master, appName):\n","    ## use findSpark package to make a Spark Context available\n","\n","    import findspark\n","    findspark.init()\n","            \n","    \n","    from pyspark import SparkContext\n","    from pyspark.conf import SparkConf \n","    from pyspark.sql import SparkSession # working with dataframe\n","    \n","    SparkContext.setSystemProperty('spark.executor.memory', '15g')\n","    SparkContext.setSystemProperty('spark.driver.memory', '15g')\n","    spark_context = SparkContext(master=master, appName=appName)\n","    spark_session = SparkSession(spark_context)\n","    \n","    print(\"Init Spark successfully!\")\n","    \n","    return spark_context, spark_session\n","\n","spark_context, spark_session = init_spark(\"local\", \"Classification - Womens E-Commerce Clothing Reviews\")"]},{"cell_type":"markdown","metadata":{"id":"_1m3eS8pccxY"},"source":["## Select necessary columns to convert to pyspark dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqUO_LbhcRb3"},"outputs":[],"source":["preprocessed_df = rating_class[['Recommended IND', 'ReviewDescription', 'Binned Rating']]"]},{"cell_type":"markdown","metadata":{"id":"EDHGi4qbc2iX"},"source":["## Convert from pandas df to spark df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hx8Rrr0jc58W","outputId":"8c10108d-67b6-48dd-83c5-e50032641105"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------+--------------------+-------------+\n","|Recommended IND|   ReviewDescription|Binned Rating|\n","+---------------+--------------------+-------------+\n","|            1.0|absolutely wonder...|            1|\n","|            1.0|love this dress i...|            1|\n","|            0.0|some design flaws...|            0|\n","|            1.0|my favorite buy i...|            1|\n","|            1.0|flattering shirt ...|            1|\n","|            0.0|not for the very ...|            0|\n","|            1.0|fun i this in my ...|            1|\n","|            1.0|surprisingly goes...|            1|\n","|            1.0|flattering i love...|            1|\n","|            1.0|such a fun dress ...|            1|\n","|            1.0|this dress is per...|            1|\n","|            1.0|perfect more and ...|            1|\n","|            1.0|runs big bought t...|            1|\n","|            1.0|pretty party dres...|            0|\n","|            1.0|nice but not for ...|            1|\n","|            1.0|you need to be at...|            0|\n","|            1.0|looks great with ...|            1|\n","|            1.0|super cute and co...|            1|\n","|            1.0|stylish and comfo...|            1|\n","|            1.0|cute crisp shirt ...|            1|\n","+---------------+--------------------+-------------+\n","only showing top 20 rows\n","\n"]}],"source":["preprocessed_spdf = spark_session.createDataFrame(preprocessed_df)\n","preprocessed_spdf.show()"]},{"cell_type":"markdown","metadata":{"id":"0JjK_MMYgNNs"},"source":["# Text processing"]},{"cell_type":"markdown","metadata":{"id":"ZgK6FbkEk3c4"},"source":["## Stop word removal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gKEaBjdlBJI"},"outputs":[],"source":["## create ad-hoc list with user define based on domain\n","stopwordList=['']\n","\n","## setting up stop words\n","stopwordList.extend(StopWordsRemover().getStopWords())\n","stopwordList = list(set(stopwordList))"]},{"cell_type":"markdown","metadata":{"id":"rDe8NabKlysv"},"source":["## Prepare pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2i5xD-fl1kC"},"outputs":[],"source":["## Detail for each step function is provided in the report\n","## 1st step\n","#topic_indexer = StringIndexer(inputCol='topic_name',\n","#                             outputCol='index_topic')\n","\n","## 2nd step\n","tokenizer = Tokenizer(inputCol='ReviewDescription',\n","                     outputCol='tokenized_ReviewDescription')\n","\n","## 3rd step\n","stopremove = StopWordsRemover(inputCol='tokenized_ReviewDescription',\n","                            outputCol='stop_ReviewDescription',\n","                            stopWords=stopwordList)\n","\n","## 4th step\n","count_vec = CountVectorizer(inputCol='stop_ReviewDescription',\n","                           outputCol='vector_ReviewDescription')\n","\n","## 5th step\n","idf = IDF(inputCol='vector_ReviewDescription',\n","          outputCol='processed_ReviewDescription')\n","    \n","## define pipeline\n","#pipeline = Pipeline(stages=[topic_indexer, tokenizer, stopremove, count_vec, idf])\n","\n","pipeline = Pipeline(stages=[tokenizer,\n","                            stopremove,\n","                            count_vec,\n","                            idf])\n","\n","## fit and transform\n","processed_features = pipeline.fit(preprocessed_spdf)\n","features = processed_features.transform(preprocessed_spdf)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0AgdRWbmDFh","outputId":"e3fc9890-bc51-4738-b10c-bbf460032249"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Recommended IND',\n"," 'ReviewDescription',\n"," 'Binned Rating',\n"," 'tokenized_ReviewDescription',\n"," 'stop_ReviewDescription',\n"," 'vector_ReviewDescription',\n"," 'processed_ReviewDescription']"]},"metadata":{},"execution_count":31}],"source":["### for easy copy paste column names\n","features.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3M6XoAQfmWiv","outputId":"d1ddb3df-8722-403c-8702-1259d9ca756f"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+\n","|Recommended IND|   ReviewDescription|Binned Rating|tokenized_ReviewDescription|stop_ReviewDescription|vector_ReviewDescription|processed_ReviewDescription|\n","+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+\n","|            1.0|absolutely wonder...|            1|       [absolutely, wond...|  [absolutely, wond...|    (1422,[23,166,384...|       (1422,[23,166,384...|\n","|            1.0|love this dress i...|            1|       [love, this, dres...|  [love, dress, pre...|    (1422,[0,1,8,18,1...|       (1422,[0,1,8,18,1...|\n","|            0.0|some design flaws...|            0|       [some, design, fl...|  [design, flaws, h...|    (1422,[0,2,3,5,10...|       (1422,[0,2,3,5,10...|\n","|            1.0|my favorite buy i...|            1|       [my, favorite, bu...|  [favorite, buy, l...|    (1422,[1,4,7,62,1...|       (1422,[1,4,7,62,1...|\n","|            1.0|flattering shirt ...|            1|       [flattering, shir...|  [flattering, shir...|    (1422,[1,7,13,17,...|       (1422,[1,7,13,17,...|\n","+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+\n","only showing top 5 rows\n","\n"]}],"source":["features.show(5)"]},{"cell_type":"markdown","metadata":{"id":"9Wdk__UMoLq_"},"source":["# Prepare input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp94bUsdoNch"},"outputs":[],"source":["## assembling all features into an input\n","assembler = VectorAssembler(inputCols=['Recommended IND', 'processed_ReviewDescription'],\n","                           outputCol='features')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKKiRlC5o-I6"},"outputs":[],"source":["## transform the assembler\n","features = assembler.transform(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G-Rlh7HpIVK","outputId":"a4dbc675-b5eb-424c-a96b-7bd1d3ed6125"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+--------------------+\n","|Recommended IND|   ReviewDescription|Binned Rating|tokenized_ReviewDescription|stop_ReviewDescription|vector_ReviewDescription|processed_ReviewDescription|            features|\n","+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+--------------------+\n","|            1.0|absolutely wonder...|            1|       [absolutely, wond...|  [absolutely, wond...|    (1422,[23,166,384...|       (1422,[23,166,384...|(1423,[0,24,167,3...|\n","|            1.0|love this dress i...|            1|       [love, this, dres...|  [love, dress, pre...|    (1422,[0,1,8,18,1...|       (1422,[0,1,8,18,1...|(1423,[0,1,2,9,19...|\n","|            0.0|some design flaws...|            0|       [some, design, fl...|  [design, flaws, h...|    (1422,[0,2,3,5,10...|       (1422,[0,2,3,5,10...|(1423,[1,3,4,6,11...|\n","|            1.0|my favorite buy i...|            1|       [my, favorite, bu...|  [favorite, buy, l...|    (1422,[1,4,7,62,1...|       (1422,[1,4,7,62,1...|(1423,[0,2,5,8,63...|\n","|            1.0|flattering shirt ...|            1|       [flattering, shir...|  [flattering, shir...|    (1422,[1,7,13,17,...|       (1422,[1,7,13,17,...|(1423,[0,2,8,14,1...|\n","+---------------+--------------------+-------------+---------------------------+----------------------+------------------------+---------------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["features.show(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2gGJa1SpQ1C","outputId":"c0a94528-bb45-4e34-9c54-45247c20013a"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+-------------+\n","|            features|Binned Rating|\n","+--------------------+-------------+\n","|(1423,[0,24,167,3...|            1|\n","|(1423,[0,1,2,9,19...|            1|\n","|(1423,[1,3,4,6,11...|            0|\n","|(1423,[0,2,5,8,63...|            1|\n","|(1423,[0,2,8,14,1...|            1|\n","+--------------------+-------------+\n","only showing top 5 rows\n","\n"]}],"source":["## select the input features\n","model_data = features.select('features', 'Binned Rating')\n","model_data.show(5)"]},{"cell_type":"markdown","metadata":{"id":"syEBzo0Zpcpx"},"source":["# Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53GLkW3PpcR-"},"outputs":[],"source":["## train test splitting\n","(training, test) = model_data.randomSplit([0.7,0.3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEk0YYYIpoKx"},"outputs":[],"source":["## create a list of classification models\n","lg = LogisticRegression(labelCol='Binned Rating', featuresCol = 'features')\n","nb = NaiveBayes(labelCol='Binned Rating', featuresCol = 'features', modelType='multinomial')\n","dt = DecisionTreeClassifier(labelCol='Binned Rating', featuresCol = 'features')\n","rf = RandomForestClassifier(labelCol='Binned Rating', featuresCol = 'features')\n","gb = GBTClassifier(labelCol='Binned Rating', featuresCol = 'features')\n","#mp = MultilayerPerceptronClassifier(labelCol='Binned Rating', featuresCol = 'features')\n","sv = LinearSVC(labelCol='Binned Rating', featuresCol = 'features')\n","lst_model =[lg, nb, dt, rf]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDoWr6jNqTK3"},"outputs":[],"source":["## create accuracy list\n","global list_acc \n","list_acc = []\n","global list_pre \n","list_pre = []\n","global list_rec \n","list_rec = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMvNZbGPqWqS"},"outputs":[],"source":["def build_model_classification(model, training, test):\n","    \n","    fitted_model = model.fit(training)\n","\n","    test_model = fitted_model.transform(test)\n","\n","    acc_evaluator = MulticlassClassificationEvaluator(labelCol = 'Binned Rating',\n","                                                 predictionCol = 'prediction',\n","                                                 metricName = 'accuracy')\n","\n","    accuracy = acc_evaluator.evaluate(test_model)\n","\n","    list_acc.append(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cx8ttsbNqrEh"},"outputs":[],"source":["build_model_classification(lg, training, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsxjMKBtqse3"},"outputs":[],"source":["build_model_classification(nb, training, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkgs6U9LquT2"},"outputs":[],"source":["build_model_classification(dt, training, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNtBHXs5qv4B"},"outputs":[],"source":["build_model_classification(rf, training, test)"]},{"cell_type":"code","source":["build_model_classification(gb, training, test)"],"metadata":{"id":"DKIVPypY3Wyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#build_model_classification(mp, training, test)"],"metadata":{"id":"CkWmoNRt3X5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["build_model_classification(sv, training, test)"],"metadata":{"id":"4uw6MOmg3YvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvEkhmDjqxZD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b1bcf53-511e-47a8-a8ce-a1ed80eef0fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.9107718167810618,\n"," 0.866928141196246,\n"," 0.9359854321333521,\n"," 0.7989914553859084,\n"," 0.9357052808516599,\n"," 0.9221179436895924]"]},"metadata":{},"execution_count":52}],"source":["list_acc"]},{"cell_type":"code","source":["list_models = ['Logistic Regression',\n","               'Naive Bayes',\n","               'Decision Tree',\n","               'Random Forest',\n","               'GBT',\n","               'SVC']"],"metadata":{"id":"dTsNJce8uHCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df = pd.DataFrame(\n","    {'model': list_models,\n","     'accuracy': list_acc\n","    })"],"metadata":{"id":"Z_8tmJXGrH8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.sort_values(by='accuracy', ascending=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"g4hWi5vSuelj","outputId":"dd4be469-6af0-4900-8e9a-a4530b5ece06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 model  accuracy\n","2        Decision Tree  0.935985\n","4                  GBT  0.935705\n","5                  SVC  0.922118\n","0  Logistic Regression  0.910772\n","1          Naive Bayes  0.866928\n","3        Random Forest  0.798991"],"text/html":["\n","  <div id=\"df-6ca9340d-7a74-4c22-8e42-5532fe516b5d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Decision Tree</td>\n","      <td>0.935985</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GBT</td>\n","      <td>0.935705</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>SVC</td>\n","      <td>0.922118</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Logistic Regression</td>\n","      <td>0.910772</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Naive Bayes</td>\n","      <td>0.866928</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Random Forest</td>\n","      <td>0.798991</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ca9340d-7a74-4c22-8e42-5532fe516b5d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ca9340d-7a74-4c22-8e42-5532fe516b5d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ca9340d-7a74-4c22-8e42-5532fe516b5d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":[""],"metadata":{"id":"DRuFfAC3ufsG"},"execution_count":null,"outputs":[]}]}